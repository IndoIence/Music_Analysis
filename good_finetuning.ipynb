{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tp/miniconda3/envs/mgr/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-26 15:34:19.654822: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-26 15:34:19.683494: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-26 15:34:20.159805: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from utils import get_artist, get_biggest_arts\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from torch import Tensor\n",
    "import torch\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "\n",
    "def songs_from_artists(arts, tokenizer,label2id: dict, song_limit: int = 300, ):\n",
    "    data = []\n",
    "    for art in arts:\n",
    "        for song in art.songs[:song_limit]:\n",
    "            input_ids, attention_mask = transform_text(song.lyrics, tokenizer)\n",
    "            for one_input, one_mask in zip(input_ids, attention_mask):\n",
    "                data.append({\n",
    "                    \"label\": label2id[song.artist_name],\n",
    "                    \"input_ids\": one_input.numpy(),\n",
    "                    \"attention_mask\": one_mask.numpy(),\n",
    "                })\n",
    "    return data\n",
    "\n",
    "def chunks_from_artists(arts, tokenizer,label2id: dict, song_limit: int = 300, ):\n",
    "    inputs = []\n",
    "    attentions = []\n",
    "    labels = []\n",
    "    for art in arts:\n",
    "        for song in art.songs[:song_limit]:\n",
    "            input_ids, attention_mask = transform_text(song.lyrics, tokenizer)\n",
    "            for one_input, one_mask in zip(input_ids, attention_mask):\n",
    "                    inputs.append(one_input)\n",
    "                    attentions.append(one_mask)\n",
    "                    labels.append(label2id[song.artist_name])\n",
    "    return inputs, attentions, labels\n",
    "\n",
    "def tokenize(text, tokenizer: AutoTokenizer) -> tuple[Tensor, Tensor]:\n",
    "    result = tokenizer(text, add_special_tokens=False, truncation=False, return_tensors='pt')\n",
    "    return result[\"input_ids\"][0], result[\"attention_mask\"][0]\n",
    "\n",
    "def split_overlapping(tensor: Tensor, chunk_size: int = 510, stride: int = 400, min_chunk_len = 100) -> list[Tensor]:\n",
    "    chunks = [tensor[i:i+chunk_size] for i in range(0, tensor.shape[0], stride)]\n",
    "    if len(chunks) > 1:\n",
    "        chunks = [chunk for chunk in chunks if len(chunk) >= min_chunk_len]\n",
    "    return chunks\n",
    "\n",
    "def add_special_tokens(input_chunks: list[Tensor], mask_chunks: list[Tensor]):\n",
    "    for i in range(len(input_chunks)):\n",
    "        input_chunks[i] = torch.cat([torch.tensor([101]), input_chunks[i], torch.tensor([102])])\n",
    "        mask_chunks[i] = torch.cat([torch.tensor([1]), mask_chunks[i], torch.tensor([1])])\n",
    "\n",
    "def add_padding(input_chunks: list[Tensor], mask_chunks: list[Tensor]) -> None:\n",
    "    for i in range(len(input_chunks)):\n",
    "        pad_len = 512 - input_chunks[i].shape[0]\n",
    "        input_chunks[i] = torch.cat([input_chunks[i], torch.tensor([tokenizer.pad_token_id] * pad_len)])\n",
    "        mask_chunks[i] = torch.cat([mask_chunks[i], torch.tensor([0] *pad_len)])\n",
    "        \n",
    "def stack_chunks(input_chunks: list[Tensor], mask_chunks: list[Tensor]) -> tuple[Tensor, Tensor]:\n",
    "    return torch.stack(input_chunks).long(), torch.stack(mask_chunks).int()\n",
    "\n",
    "def transform_text(\n",
    "    text: str,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    chunk_size: int = 510,\n",
    "    stride: int = 400,\n",
    "    min_chunk_len = 100,\n",
    "    ):\n",
    "    id_long, mask_long = tokenize(text, tokenizer)\n",
    "    id_chunks = split_overlapping(id_long, chunk_size, stride, min_chunk_len)\n",
    "    mask_chunks = split_overlapping(mask_long, chunk_size, stride, min_chunk_len)\n",
    "    \n",
    "    add_special_tokens(id_chunks, mask_chunks)\n",
    "    add_padding(id_chunks, mask_chunks)\n",
    "    input_ids, attention_mask = stack_chunks(id_chunks, mask_chunks)\n",
    "    return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1049/1049 [00:04<00:00, 220.22it/s].71it/s]\n",
      "sorting artists by lyrics length: 1049it [00:04, 219.92it/s]\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (722 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "top10 = get_biggest_arts(10)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "id2label ={i:label for i, label in enumerate((art.name_sanitized for art in top10))}\n",
    "label2id = {label:i for i, label in id2label.items()}\n",
    "# split the data\n",
    "\n",
    "data = songs_from_artists(top10, tokenizer, label2id)\n",
    "df = pd.DataFrame(data)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch.nn.functional as F\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=10, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss = F.nll_loss(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkatnak56\u001b[0m (\u001b[33mfirst_throw\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tp/MGR/from_gpu_server/Music_Analysis/wandb/run-20240626_153432-xw247etf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/first_throw/huggingface/runs/xw247etf' target=\"_blank\">my_awesome_model</a></strong> to <a href='https://wandb.ai/first_throw/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/first_throw/huggingface' target=\"_blank\">https://wandb.ai/first_throw/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/first_throw/huggingface/runs/xw247etf' target=\"_blank\">https://wandb.ai/first_throw/huggingface/runs/xw247etf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 20%|██        | 419/2095 [02:34<09:30,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': -11.056400299072266, 'eval_accuracy': 0.14498806682577567, 'eval_runtime': 12.6295, 'eval_samples_per_second': 132.705, 'eval_steps_per_second': 8.314, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 500/2095 [03:03<09:12,  2.89it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': -6.236, 'grad_norm': 22.738264083862305, 'learning_rate': 1.5226730310262532e-05, 'epoch': 1.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 40%|████      | 838/2095 [05:12<07:06,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': -28.195188522338867, 'eval_accuracy': 0.13484486873508353, 'eval_runtime': 12.6004, 'eval_samples_per_second': 133.011, 'eval_steps_per_second': 8.333, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 1000/2095 [06:10<06:18,  2.89it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': -24.4335, 'grad_norm': 49.09849166870117, 'learning_rate': 1.045346062052506e-05, 'epoch': 2.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 60%|██████    | 1257/2095 [07:51<04:43,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': -45.8148307800293, 'eval_accuracy': 0.13484486873508353, 'eval_runtime': 12.5051, 'eval_samples_per_second': 134.025, 'eval_steps_per_second': 8.397, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1500/2095 [09:16<03:25,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': -45.2292, 'grad_norm': 57.98971176147461, 'learning_rate': 5.68019093078759e-06, 'epoch': 3.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 80%|████████  | 1676/2095 [10:30<02:22,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': -58.77919006347656, 'eval_accuracy': 0.13484486873508353, 'eval_runtime': 12.6798, 'eval_samples_per_second': 132.179, 'eval_steps_per_second': 8.281, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 2000/2095 [12:24<00:33,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': -59.8031, 'grad_norm': 65.0184326171875, 'learning_rate': 9.069212410501194e-07, 'epoch': 4.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|██████████| 2095/2095 [13:09<00:00,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': -63.568782806396484, 'eval_accuracy': 0.13484486873508353, 'eval_runtime': 12.4826, 'eval_samples_per_second': 134.267, 'eval_steps_per_second': 8.412, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2095/2095 [13:10<00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 797.8193, 'train_samples_per_second': 42.002, 'train_steps_per_second': 2.626, 'train_loss': -35.26774558565781, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2095, training_loss=-35.26774558565781, metrics={'train_runtime': 797.8193, 'train_samples_per_second': 42.002, 'train_steps_per_second': 2.626, 'total_flos': 4439615832576000.0, 'train_loss': -35.26774558565781, 'epoch': 5.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    # push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    # tokenizer=tokenizer,\n",
    "    # data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'attention_mask', '__index_level_0__'],\n",
       "    num_rows: 1676\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'attention_mask', '__index_level_0__'],\n",
       "    num_rows: 6702\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example_song_lyrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m input_ids, attention_masks \u001b[38;5;241m=\u001b[39m transform_text(\u001b[43mexample_song_lyrics\u001b[49m[\u001b[38;5;241m0\u001b[39m], tokenizer)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'example_song_lyrics' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "input_ids, attention_masks = transform_text(example_song_lyrics[0], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 512]), torch.Size([3, 512]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape, attention_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#hot16challenge\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Wyje Wyje Bane\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Rainman\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Michael Kors\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "#CTZK\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Wunder-Baum\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Ostatnia Noc\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Pażałsta\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Biełyje Nosy\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "T-Killa\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Forever Ja\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Brodaggacio\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "69 Ziomeczków\n",
      "torch.Size([4, 512]) torch.Size([4, 512])\n",
      "#COHF\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Kot Gigant\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Tough Love\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "CMRT\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Feat. (+ Introdukcja)\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Drin za drinem\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Moja Natura\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Keptn’\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Szpanpan\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "DLS\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Czyste Szpanerstwo\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Dziup L.A.\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Streetwear\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Nie Banglasz\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Jeeebać Łaków Remix\n",
      "torch.Size([10, 512]) torch.Size([10, 512])\n",
      "Vanillalalahajs\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Big Poppa\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "John Rambo\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Martwe Ziomki\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Axamit\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Łatwopalność\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Bezgunaman\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Tak Nam Dobrze\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Iza Luiza\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "J23\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Rezzi (Lata Dans)\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Było Warto\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Gimb Money\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Polećmy Razem\n",
      "torch.Size([4, 512]) torch.Size([4, 512])\n",
      "To Coś\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Ja mam to co ty\n",
      "torch.Size([5, 512]) torch.Size([5, 512])\n",
      "Jupiter\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Dzisiaj Tak\n",
      "torch.Size([4, 512]) torch.Size([4, 512])\n",
      "Na Pierwszej Linii\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Hoespicjum\n",
      "torch.Size([4, 512]) torch.Size([4, 512])\n",
      "Melo Inferno\n",
      "torch.Size([4, 512]) torch.Size([4, 512])\n",
      "Cafe O’Belga\n",
      "torch.Size([4, 512]) torch.Size([4, 512])\n",
      "Spróbuj\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Hot18Banglasz\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Senymenalnie\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Wieczór Kawalerski Pt. 1\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Żelipapą\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Tłek\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Ryyyj\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Vanilla Ice\n",
      "torch.Size([4, 512]) torch.Size([4, 512])\n",
      "Tylko Tyle\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Cztery Benze\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Ej ziomek Remix\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Gangin’\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Stadnina\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Noji?\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Pięć Remix\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Bednius\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Boatever\n",
      "torch.Size([4, 512]) torch.Size([4, 512])\n",
      "100k Na Insta\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Kiedy Keptn\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Dyskretny Chłód 2\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Tederminacja\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Murrrda\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Mirafiori\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Najaraj Się Marią\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Allinka\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Pump Air Nikiel\n",
      "torch.Size([4, 512]) torch.Size([4, 512])\n",
      "Polonez Trapez\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "One Star\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Słek Posypany Remix\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Wydajeje\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Ola z Na Wspólnej\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Guczi Sruczi Look\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "FCMT\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Wolę się nastukać\n",
      "torch.Size([7, 512]) torch.Size([7, 512])\n",
      "Kasa\n",
      "torch.Size([4, 512]) torch.Size([4, 512])\n",
      "Tanktop\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Kara’van\n",
      "torch.Size([4, 512]) torch.Size([4, 512])\n",
      "22\" AC Schnitzer\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Klaser\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Ten Bit Jak Mobb Deep (199X)\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Fame Lover\n",
      "torch.Size([4, 512]) torch.Size([4, 512])\n",
      "Jeeebać Łaków\n",
      "torch.Size([4, 512]) torch.Size([4, 512])\n",
      "Moniuszko Flow\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Kurort Rolson\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "P.N.K.Ś.K.J.Z.I.N.Z.S.S.B.C.N.T.Z.I.J.M.Z.T.P.B.S.C\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Keptn’ Jack\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Autowpierdol\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Hamuj Piętą\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n",
      "Tańcuj\n",
      "torch.Size([3, 512]) torch.Size([3, 512])\n",
      "Przez Feeejm\n",
      "torch.Size([2, 512]) torch.Size([2, 512])\n"
     ]
    }
   ],
   "source": [
    "for song in get_artist(\"Tede\").songs[:100]:\n",
    "    print(song.title)\n",
    "    input_ids, attention_masks = transform_text(song.get_clean_song_lyrics(), tokenizer)\n",
    "    print(input_ids.shape, attention_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_biggest_arts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top30_arts = get_biggest_arts(30)\n",
    "songs = [song for art in top30_arts for song in art.songs[:200] if song.get_clean_song_lyrics() != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = chunk_text(example_song_lyrics[0], tokenizer)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing == tokenizer.decode(tokenizer.encode(testing, add_special_tokens=False, truncation=False, return_tensors='pt')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1001,  1001, 12098,  6200,  6583,  2480,  4213, 24098,  2666,  8962,\n",
      "          6633, 17491,  3217,  3676, 27838,  9761,  5004,  1010,  2000,  6448,\n",
      "          4355,  2401,  1039,  4143,  6342, 14855,  2243, 29250,  2480,  2532,\n",
      "          1062, 13476,  6200,  2278,  1012,  1012,  1012,  1012, 13970, 14756,\n",
      "          7367, 11968,  2063,  5207,  5004, 21469,  2050,  1055,  2480,  9739,\n",
      "          2226, 12849, 23344,  2102,  8034,  2022,  2480,  2933,  2226,  8945,\n",
      "          5003,  2213, 24185, 19666,  2100,  5353, 14855,  2243,  2793,  2050,\n",
      "         17235,  1052, 22123,  6305,  6583, 12170, 11283,  1039,  9096, 24185,\n",
      "          2094,  3489,  1039,  9096,  1105, 17994,  2063,  1029,  2000,  2026,\n",
      "         24185, 13728,  2100,  1105, 17994,  2063,  1105, 17994,  2050, 14768,\n",
      "          1010,  5939,  1010, 22064,  3501,  1055, 18818, 17994,  6305,  6187,\n",
      "         18818,  2063,  1059, 27006,  7033,  2617,  6776,  2000,  5003,  2213,\n",
      "         27006,  2072,  2373, 27838,  3520,  2011,  2213, 10975, 24506, 28534,\n",
      "         27966,  2050, 18818, 14163,  9096,  3489, 12849, 12273,  9096,  9033,\n",
      "          2063,  5353,  1010, 29250, 23749,  2050,  5939,  2094, 14272,  2078,\n",
      "          1059,  2100,  3501,  2094, 14272,  1010, 27838,  6583, 13113,  2522,\n",
      "          2015,  9748, 10624,  2860,  1062,  2100, 23402,  2000,  1062,  2100,\n",
      "         23402,  1012, 10958,  2480,  1055,  9096,  9818,  2666,  3501, 10958,\n",
      "          2480, 24185, 19666,  2666,  3501, 11867, 16366, 22895,  2666, 13433,\n",
      "          8569,  3900,  2213,  9033,  2063,  6519,  2050, 13433,  9358,  6824,\n",
      "          2000,  3520,  2080, 10975,  9096,  3501,  2094, 14272,  1010,  1039,\n",
      "          4143,  2015,  4830,  3501,  2079, 16686,  2050,  2771,  1011,  2149,\n",
      "          6873,  2912,  3900,  2213, 22564, 27544, 14272,  2000,  1062, 18994,\n",
      "          5937, 19817,  9096,  2213,  9033,  2063,  1010, 12403, 17130,  1062,\n",
      "         13970,  8737, 10278,  2072,  2079,  5631,  1051, 18927,  3771,  9305,\n",
      "          2050,  2771,  1010,  3393,  3401, 17214, 13433,  2000, 24401,  3630,\n",
      "          1042, 11439, 15333, 24700,  6305, 24401,  3630,  1042, 11439,  1010,\n",
      "         24401,  3630, 15333, 24700,  6305,  1042, 11439,  2000, 15333,  3367,\n",
      "          7367,  2094,  3630, 27178,  2080,  3393,  3401, 15333, 24700,  6305,\n",
      "         24401,  3630,  1042, 11439,  1010, 24401,  3630,  1042, 11439, 15333,\n",
      "         24700,  6305, 24401,  3630,  1042, 11439, 15333, 24700,  6305,  1010,\n",
      "          1051,  1039,  4143,  2015,  1052, 18818,  6038,  2666,  1010,  1052,\n",
      "         18818,  6038,  2666,  1037,  5939,  1059,  2100,  6460,  1059,  2100,\n",
      "          6460, 25163, 16137,  2480,  1059,  2100,  6460,  1059,  2100,  6460,\n",
      "         25163, 16137,  2480,  1059,  2000, 27838,  1052, 18818,  6038,  2666,\n",
      "          1039,  4143,  2015,  1039,  4143,  2015,  1052, 18818,  6038,  2666,\n",
      "          1010,  1052, 18818,  6038,  2666,  1037,  5939,  1059,  2100,  6460,\n",
      "          1059,  2100,  6460, 25163, 16137,  2480,  1059,  2100,  6460,  1059,\n",
      "          2100,  6460, 25163, 16137,  2480,  1059,  2100,  6460, 27543, 16137,\n",
      "          2480,  1039,  4143,  2015,  1052, 18818,  6038,  2666,  1010,  1052,\n",
      "         18818,  6038,  2666,  1037,  5939,  1059,  2100,  6460,  1059,  2100,\n",
      "          6460, 25163, 16137,  2480,  1059,  2100,  6460,  1059,  2100,  6460,\n",
      "         25163, 16137,  2480,  1059,  2000, 27838,  1052, 18818,  6038,  2666,\n",
      "          1039,  4143,  2015,  1039,  4143,  2015,  1052, 18818,  6038,  2666,\n",
      "          1010,  1052, 18818,  6038,  2666,  1037,  5939,  1059,  2100,  6460,\n",
      "          1059,  2100,  6460, 25163, 16137,  2480,  1059,  2100,  6460,  1059,\n",
      "          2100,  6460, 25163, 16137,  2480,  1059,  2100,  6460, 27543, 16137,\n",
      "          2480]])\n",
      "# # arnia nazwa mnie potem podroba ze stanow, to kwestia czasu jak zaczna zwalniac.... kupie se pare jordanow dla szpanu kompletnie bez planu bo mam wolny weekend jak beda nas pytac na bibie czy wodke czy łyche? to my wolmy łyche łycha sour, ty, nwj słychac całe w takich momentach to mam taki power ze sam bym przekrzyczał muzyke konczy sie weekend, zaczyna tydzien wyjdzie, ze nagram cos bangerow zycie to zycie. raz szybciej raz wolniej spokojnie pobujam sie fura po centrum to samo przyjdzie, czas daj do maja mi - uspokajam ich narazie to ziomek trzym sie, spadam z kumplami do miami odpierdala mi, lece tam po to jedno foto jebnac jedno foto, jedno jebnac foto to jest sedno oto lece jebnac jedno foto, jedno foto jebnac jedno foto jebnac, o czas płynie, płynie a ty wyje wyje bane masz wyje wyje bane masz w to ze płynie czas czas płynie, płynie a ty wyje wyje bane masz wyje wyje bane masz wyjebane masz czas płynie, płynie a ty wyje wyje bane masz wyje wyje bane masz w to ze płynie czas czas płynie, płynie a ty wyje wyje bane masz wyje wyje bane masz wyjebane masz\n",
      "##arnia nazwa mnie potem podroba ze stanow, to kwestia czasu jak zaczna zwalniac.... kupie se pare jordanow dla szpanu kompletnie bez planu bo mam wolny weekend jak beda nas pytac na bibie czy wodke czy łyche? to my wolmy łyche łycha sour, ty, nwj słychac całe w takich momentach to mam taki power ze sam bym przekrzyczał muzyke konczy sie weekend, zaczyna tydzien wyjdzie, ze nagram cos bangerow zycie to zycie. raz szybciej raz wolniej spokojnie pobujam sie fura po centrum to samo przyjdzie, czas daj do maja mi - uspokajam ich narazie to ziomek trzym sie, spadam z kumplami do miami odpierdala mi, lece tam po to jedno foto jebnac jedno foto, jedno jebnac foto to jest sedno oto lece jebnac jedno foto, jedno foto jebnac jedno foto jebnac, o czas płynie, płynie a ty wyje wyje bane masz wyje wyje bane masz w to ze płynie czas czas płynie, płynie a ty wyje wyje bane masz wyje wyje bane masz wyjebane masz czas płynie, płynie a ty wyje wyje bane masz wyje wyje bane masz w to ze płynie czas czas płynie, płynie a ty wyje wyje bane masz wyje wyje bane masz wyjebane masz\n"
     ]
    }
   ],
   "source": [
    "testing_encoded = tokenizer.encode(testing, add_special_tokens=False, truncation=False, return_tensors='pt')\n",
    "testing_decoded = tokenizer.decode(testing_encoded[0])\n",
    "print(testing_encoded)\n",
    "print(testing_decoded)\n",
    "print(testing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mgr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
